# training_a_new_tokenizer for Python 
Here I've shared how to train a new tokenizer of computer language, namely Python  
